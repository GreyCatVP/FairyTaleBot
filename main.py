
import os
import httpx
import asyncio
import re
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

HEADERS = {
    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
    "HTTP-Referer": "https://t.me/SkazochnikTimoshaBot",
    "Content-Type": "application/json"
}

MODEL = "deepseek/deepseek-r1-0528:free"

async def gpt_call(messages, max_tokens=2048):
    payload = {
        "model": MODEL,
        "messages": messages,
        "temperature": 0.8,
        "max_tokens": max_tokens
    }
    try:
        async with httpx.AsyncClient(timeout=90.0) as client:
            r = await client.post("https://openrouter.ai/api/v1/chat/completions", headers=HEADERS, json=payload)
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"].strip()
    except httpx.HTTPStatusError as e:
        if e.response.status_code == 429:
            return "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ ‚òï"
        raise

def is_truncated(text):
    last_word = re.split(r'\s+', text.strip())[-1]
    return not re.match(r'^[–ê-–Ø–∞-—èA-Za-z0-9—ë–Å\-‚Äì‚Äî"‚Äú‚Äù¬´¬ª!?.,;:‚Ä¶]+$', last_word)

async def generate_fairytale():
    base_prompt = [
        {"role": "system", "content": (
            "–¢—ã ‚Äî —Å–∫–∞–∑–æ—á–Ω–∏–∫. –ü–∏—à–∏ –¥–æ–±—Ä—ã–µ, –ø–æ–Ω—è—Ç–Ω—ã–µ —Å–∫–∞–∑–∫–∏ –¥–ª—è –¥–µ—Ç–µ–π 3‚Äì8 –ª–µ—Ç (—á–∏—Ç–∞—é—Ç —Ä–æ–¥–∏—Ç–µ–ª–∏). "
            "–ì–ª–∞–≤–Ω–æ–µ ‚Äî —Å—é–∂–µ—Ç, —ç–º–æ—Ü–∏–∏, —Ñ–∏–Ω–∞–ª —Å –º–æ—Ä–∞–ª—å—é. –ò–∑–±–µ–≥–∞–π –¥–ª–∏–Ω–Ω—ã—Ö –æ–ø–∏—Å–∞–Ω–∏–π –∏ –∏–∑–±—ã—Ç–æ—á–Ω—ã—Ö –º–µ—Ç–∞—Ñ–æ—Ä. "
            "–ü–∏—à–∏ –ª–∞–∫–æ–Ω–∏—á–Ω–æ, –æ–±—Ä–∞–∑–Ω–æ, –Ω–æ –ø—Ä–æ—Å—Ç–æ. –û–±—ä—ë–º ‚Äî 1500‚Äì2000 —Å–∏–º–≤–æ–ª–æ–≤."
        )},
        {"role": "user", "content": "–†–∞—Å—Å–∫–∞–∂–∏ –¥–æ–±—Ä—É—é —Å–∫–∞–∑–∫—É."}
    ]

    story = await gpt_call(base_prompt)
    if "–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤" in story:
        return story

    verify_prompt = [{"role": "user", "content": f"–í–æ—Ç —Å–∫–∞–∑–∫–∞:\n\n{story}\n\n–°–∫–∞–∂–∏ —á–µ—Å—Ç–Ω–æ, –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –ª–∏ –æ–Ω–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏ –∏ —Ö—É–¥–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ? –û—Ç–≤–µ—Ç—å —Ç–æ–ª—å–∫–æ '–¥–∞' –∏–ª–∏ '–Ω–µ—Ç'."}]
    verdict = await gpt_call(verify_prompt, max_tokens=10)
    if verdict.lower().strip().startswith("–Ω"):
        cont_prompt = base_prompt + [{"role": "assistant", "content": story}, {"role": "user", "content": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–¥–æ–ª–∂–∏ —Å–∫–∞–∑–∫—É –¥–æ –µ—ë –ø–æ–ª–Ω–æ–≥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è —Å —Ñ–∏–Ω–∞–ª–æ–º –∏ –º–æ—Ä–∞–ª—å—é."}]
        continuation = await gpt_call(cont_prompt)
        story += "\n" + continuation

    last_line = story.strip().split("\n")[-1].lower()
    if any(last_line.endswith(w) for w in ["–ª–∞", "–µ–ª", "–ª—Å—è", "–∞–ª–∞", "–ª–∏", "–≤—Å—ë", "–Ω–µ—Ç"]) or len(last_line.split()) < 5 or is_truncated(story):
        final_prompt = base_prompt + [{"role": "assistant", "content": story}, {"role": "user", "content": "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–ø–∏—à–∏ —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Å—Ü–µ–Ω—É. –ì–µ—Ä–æ–∏ —É–∂–µ —Å–æ–±—Ä–∞–ª–∏—Å—å. –î–æ–±–∞–≤—å, –∫–∞–∫ –æ–Ω–∏ —á—É–≤—Å—Ç–≤—É—é—Ç —Å–µ–±—è, —á—Ç–æ –ø–æ–Ω—è–ª–∏, –∏ –∫–∞–∫–æ–π –≤—ã–≤–æ–¥ –æ—Å—Ç–∞–ª—Å—è."}]
        final_piece = await gpt_call(final_prompt)
        story += "\n" + final_piece

    if not story.strip().endswith("–í–æ—Ç –∏ —Å–∫–∞–∑–∫–µ –∫–æ–Ω–µ—Ü. ‚ú®"):
        story += "\n\n–í–æ—Ç –∏ —Å–∫–∞–∑–∫–µ –∫–æ–Ω–µ—Ü. ‚ú®"

    return story

def split_story(text, max_length=4096):
    parts = []
    current = ""
    for paragraph in text.split("\n"):
        if len(current) + len(paragraph) + 1 > max_length:
            parts.append(current)
            current = paragraph
        else:
            current += "\n" + paragraph
    if current:
        parts.append(current)
    return parts

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü—Ä–∏–≤–µ—Ç! –Ø ‚Äî –°–∫–∞–∑–æ—á–Ω–∏–∫ –¢–∏–º–æ—à–∞. ‚ú®\n–ù–∞–ø–∏—à–∏ /skazka ‚Äî –∏ —è —Ä–∞—Å—Å–∫–∞–∂—É —Ç–µ–±–µ –¥–æ–±—Ä—É—é —Å–∫–∞–∑–∫—É.")

async def skazka(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("–ü–æ–≥–æ–¥–∏ –Ω–µ–º–Ω–æ–≥–æ... —è –≤—Å–ø–æ–º–∏–Ω–∞—é —Å–∫–∞–∑–∫—É... ‚òï")
    story = await generate_fairytale()
    parts = split_story(story)
    for i, part in enumerate(parts):
        header = f"üìò –ß–∞—Å—Ç—å {i+1}/{len(parts)}\n" if len(parts) > 1 else ""
        await update.message.reply_text(header + part.strip())

if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("skazka", skazka))

    import threading
    from http.server import BaseHTTPRequestHandler, HTTPServer

    class DummyHandler(BaseHTTPRequestHandler):
        def do_GET(self):
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b'Service is up')
        def do_HEAD(self):
            self.send_response(200)
            self.end_headers()

    def run_dummy_server():
        server = HTTPServer(('0.0.0.0', 8080), DummyHandler)
        server.serve_forever()

    threading.Thread(target=run_dummy_server, daemon=True).start()
    app.run_polling()
