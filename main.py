
import os
import re
import httpx
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

HEADERS = {
    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
    "HTTP-Referer": "https://t.me/SkazochnikTimoshaBot",
    "Content-Type": "application/json"
}

MAX_LENGTH = 4096

def split_text_smart(text, max_len=MAX_LENGTH):
    paragraphs = [p.strip() for p in text.split("\n") if p.strip()]
    chunks = []
    current = ""

    for para in paragraphs:
        if len(para) > max_len:
            sentences = re.split(r'(?<=[.!?â€¦]) +', para)
            for sentence in sentences:
                if len(current) + len(sentence) + 1 > max_len:
                    chunks.append(current.strip())
                    current = sentence
                else:
                    current += " " + sentence
        else:
            if len(current) + len(para) + 2 > max_len:
                chunks.append(current.strip())
                current = para
            else:
                current += "\n" + para

    if current.strip():
        chunks.append(current.strip())
    return chunks

async def request_gpt(messages: list, max_tokens=2000):
    payload = {
        "model": "deepseek/deepseek-r1-0528:free",
        "max_tokens": max_tokens,
        "messages": messages
    }
    async with httpx.AsyncClient(timeout=90.0) as client:
        response = await client.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=HEADERS,
            json=payload
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()

async def check_story_completion(story_text: str) -> bool:
    check_messages = [
        {
            "role": "system",
            "content": (
                "Ğ¢Ñ‹ â€” Ğ»Ğ¸Ñ‚ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ Ñ€ĞµĞ´Ğ°ĞºÑ‚Ğ¾Ñ€. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ğ¾Ñ†ĞµĞ½Ğ¸Ñ‚ÑŒ, Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ğ»Ğ¸ ÑĞºĞ°Ğ·ĞºĞ°. "
                "Ğ•ÑĞ»Ğ¸ Ğ¾Ğ½Ğ° Ğ¾Ğ±Ğ¾Ñ€Ğ²Ğ°Ğ½Ğ° Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑƒÑĞ»Ğ¾Ğ²Ğµ, Ğ½ĞµĞ´Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ° Ğ¸Ğ»Ğ¸ ÑĞ²Ğ½Ğ¾ Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½Ğ¸Ñ â€” ÑĞºĞ°Ğ¶Ğ¸ 'Ğ½ĞµÑ‚'. "
                "Ğ•ÑĞ»Ğ¸ ÑĞºĞ°Ğ·ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ‡ĞµÑĞºĞ¸ Ğ¸ Ñ…ÑƒĞ´Ğ¾Ğ¶ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° â€” ÑĞºĞ°Ğ¶Ğ¸ 'Ğ´Ğ°'. Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¾Ğ´Ğ½Ğ¾ ÑĞ»Ğ¾Ğ²Ğ¾."
            )
        },
        {
            "role": "user",
            "content": f"Ğ’Ğ¾Ñ‚ ÑĞºĞ°Ğ·ĞºĞ°:\n\n{story_text}\n\nĞ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ° Ğ»Ğ¸ Ğ¾Ğ½Ğ°?"
        }
    ]
    reply = await request_gpt(check_messages, max_tokens=10)
    return "Ğ´Ğ°" in reply.lower()

def ensure_ending(story: str):
    if not story.strip().endswith("Ğ’Ğ¾Ñ‚ Ğ¸ ÑĞºĞ°Ğ·ĞºĞµ ĞºĞ¾Ğ½ĞµÑ†. âœ¨"):
        story += "\n\nĞ’Ğ¾Ñ‚ Ğ¸ ÑĞºĞ°Ğ·ĞºĞµ ĞºĞ¾Ğ½ĞµÑ†. âœ¨"
    return story

async def generate_fairytale():
    base_messages = [
        {
            "role": "system",
            "content": (
                "Ğ¢Ñ‹ â€” ÑĞºĞ°Ğ·Ğ¾Ñ‡Ğ½Ğ¸Ğº. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ñ€Ğ°ÑÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğµ, Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ñ‹Ğµ ÑĞºĞ°Ğ·ĞºĞ¸ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹. "
                "Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ: Ğ´ĞµÑ‚Ğ¸ 3â€“8 Ğ»ĞµÑ‚, Ñ‡Ğ¸Ñ‚Ğ°ÑÑ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸. "
                "Ğ¡ĞºĞ°Ğ·ĞºĞ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½Ğ½Ğ¾Ğ¹, Ñ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ñ€Ğ°Ğ»ÑŒÑ. ĞĞµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞºĞ°Ğ·ĞºĞ¸. "
                "Ğ–ĞµĞ»Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ¾Ğ±ÑŠÑ‘Ğ¼ â€” Ğ¾Ñ‚ 1500 Ğ´Ğ¾ 2000 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²."
            )
        },
        {
            "role": "user",
            "content": "Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ ÑĞºĞ°Ğ·ĞºÑƒ."
        }
    ]

    try:
        story = await request_gpt(base_messages)
        print(f"\n=== GPT Ğ¡ĞºĞ°Ğ·ĞºĞ° ===\n{story}\n")

        if await check_story_completion(story):
            return ensure_ending(story)
        else:
            print("â­ GPT ÑĞ°Ğ¼ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°Ğ» Ğ¾Ğ±Ñ€Ñ‹Ğ² â€” Ğ´Ğ¾Ğ·Ğ°Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°ĞµĞ¼ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ğµ...")
            continuation_messages = [
                *base_messages,
                {
                    "role": "assistant",
                    "content": story
                },
                {
                    "role": "user",
                    "content": "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸ ÑĞºĞ°Ğ·ĞºÑƒ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ°, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ» Ğ¸ Ğ¼Ğ¾Ñ€Ğ°Ğ»ÑŒ."
                }
            ]
            continuation = await request_gpt(continuation_messages, max_tokens=600)
            return ensure_ending(story + "\n" + continuation)

    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ â€” {e}")
        return "Ğ¡ĞºĞ°Ğ·ĞºĞ° ÑĞ±ĞµĞ¶Ğ°Ğ»Ğ° Ğ² Ğ»ĞµÑ... ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ· Ğ¿Ğ¾Ğ·Ğ¶Ğµ ğŸ¾"

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ â€” Ğ¡ĞºĞ°Ğ·Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞ°. âœ¨\nĞĞ°Ğ¿Ğ¸ÑˆĞ¸ /skazka â€” Ğ¸ Ñ Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ñƒ Ñ‚ĞµĞ±Ğµ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ ÑĞºĞ°Ğ·ĞºÑƒ."
    )

async def skazka(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ¸ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾... Ñ Ğ²ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ ÑĞºĞ°Ğ·ĞºÑƒ... â˜•")
    story = await generate_fairytale()
    parts = split_text_smart(story)

    for i, part in enumerate(parts, start=1):
        if len(parts) > 1:
            header = f"ğŸ“˜ Ğ§Ğ°ÑÑ‚ÑŒ {i}/{len(parts)}\n"
        else:
            header = ""
        await update.message.reply_text(header + part)

if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("skazka", skazka))

    import threading
    from http.server import BaseHTTPRequestHandler, HTTPServer

    class DummyHandler(BaseHTTPRequestHandler):
        def do_GET(self):
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b'Service is up')

        def do_HEAD(self):
            self.send_response(200)
            self.end_headers()

    def run_dummy_server():
        server = HTTPServer(('0.0.0.0', 8080), DummyHandler)
        server.serve_forever()

    threading.Thread(target=run_dummy_server, daemon=True).start()
    app.run_polling()
