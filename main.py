import os
import httpx
from telegram import Update
from telegram.ext import ApplicationBuilder, CommandHandler, ContextTypes

BOT_TOKEN = os.getenv("BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

HEADERS = {
    "Authorization": f"Bearer {OPENROUTER_API_KEY}",
    "HTTP-Referer": "https://t.me/SkazochnikTimoshaBot",
    "Content-Type": "application/json"
}

ENDINGS = [
    "Ğ’Ğ¾Ñ‚ Ğ¸ ÑĞºĞ°Ğ·ĞºĞµ ĞºĞ¾Ğ½ĞµÑ†.",
    "Ğ˜ Ğ¶Ğ¸Ğ»Ğ¸ Ğ¾Ğ½Ğ¸ Ğ´Ğ¾Ğ»Ğ³Ğ¾ Ğ¸ ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²Ğ¾.",
    "Ğ˜ Ñ Ñ‚ĞµÑ… Ğ¿Ğ¾Ñ€ Ğ½Ğ¸ĞºÑ‚Ğ¾ Ğ¸Ñ… Ğ½Ğµ Ğ²Ğ¸Ğ´ĞµĞ».",
    "Ğ¡ Ñ‚ĞµÑ… Ğ¿Ğ¾Ñ€ Ğ²ÑĞµ Ğ±Ñ‹Ğ»Ğ¸ ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²Ñ‹.",
    "Ğ Ğ´Ğ¾Ğ±Ñ€Ğ°Ñ Ñ„ĞµÑ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°Ğ»Ğ° Ğ·Ğ° Ğ½Ğ¸Ğ¼Ğ¸ Ñ Ğ½ĞµĞ±Ğ°.",
    "Ğ¢Ğ°Ğº Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸Ğ»Ğ°ÑÑŒ ÑÑ‚Ğ° Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ñ.",
    "Ğ˜ Ğ²ÑÑ‘ Ğ±Ñ‹Ğ»Ğ¾ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾.",
    "Ğ Ğ¼Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ¼ÑÑ Ğ² ÑĞ»ĞµĞ´ÑƒÑÑ‰ÑƒÑ ÑĞºĞ°Ğ·ĞºÑƒ.",
    "Ğ’Ğ¾Ñ‚ Ğ¸ Ğ²ÑÑ‘, Ñ€ĞµĞ±ÑÑ‚Ğ°.",
    "Ğ’Ğ¾Ñ‚ Ñ‚Ğ°ĞºĞ°Ñ ÑĞºĞ°Ğ·ĞºĞ°.",
    "Ğ˜ Ğ±Ğ¾Ğ»ÑŒÑˆĞµ Ğ¾Ğ½Ğ¸ Ğ½Ğµ Ğ±Ğ¾ÑĞ»Ğ¸ÑÑŒ Ñ‚ĞµĞ¼Ğ½Ğ¾Ñ‚Ñ‹.",
]

MAX_LENGTH = 4096

def is_story_ok(story: str):
    return len(story) >= 1200

def is_story_finished(story: str):
    cleaned = story.strip()
    return any(end in cleaned[-300:] for end in ENDINGS) and cleaned[-1] in ".!?"

def ensure_ending(story: str):
    if not is_story_finished(story):
        story += "\n\nĞ’Ğ¾Ñ‚ Ğ¸ ÑĞºĞ°Ğ·ĞºĞµ ĞºĞ¾Ğ½ĞµÑ†. âœ¨"
    return story

def split_by_paragraphs(text):
    parts = []
    current = ""
    for paragraph in text.split("\n"):
        paragraph = paragraph.strip()
        if not paragraph:
            continue
        if len(current) + len(paragraph) + 2 > MAX_LENGTH:
            parts.append(current.strip())
            current = paragraph
        else:
            current += "\n" + paragraph
    if current.strip():
        parts.append(current.strip())
    return parts

async def request_gpt_story(messages: list, max_tokens=2000):
    payload = {
        "model": "deepseek/deepseek-r1-0528:free",
        "max_tokens": max_tokens,
        "messages": messages
    }
    async with httpx.AsyncClient(timeout=90.0) as client:
        response = await client.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=HEADERS,
            json=payload
        )
        response.raise_for_status()
        return response.json()["choices"][0]["message"]["content"].strip()

async def generate_fairytale():
    base_messages = [
        {
            "role": "system",
            "content": (
                "Ğ¢Ñ‹ â€” ÑĞºĞ°Ğ·Ğ¾Ñ‡Ğ½Ğ¸Ğº. Ğ¢Ğ²Ğ¾Ñ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ° â€” Ñ€Ğ°ÑÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğµ, Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ñ‹Ğµ ÑĞºĞ°Ğ·ĞºĞ¸ Ğ´Ğ»Ñ Ğ´ĞµÑ‚ĞµĞ¹. "
                "Ğ¦ĞµĞ»ĞµĞ²Ğ°Ñ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ: Ğ´ĞµÑ‚Ğ¸ 3â€“8 Ğ»ĞµÑ‚, Ñ‡Ğ¸Ñ‚Ğ°ÑÑ‚ Ñ€Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»Ğ¸. "
                "Ğ¡ĞºĞ°Ğ·ĞºĞ° Ğ´Ğ¾Ğ»Ğ¶Ğ½Ğ° Ğ±Ñ‹Ñ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆÑ‘Ğ½Ğ½Ğ¾Ğ¹, Ñ Ğ¿Ğ¾Ğ½ÑÑ‚Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ñ€Ğ°Ğ»ÑŒÑ. ĞĞµ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ¿Ğ¾ÑĞ»Ğµ ÑĞºĞ°Ğ·ĞºĞ¸. "
                "Ğ–ĞµĞ»Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ¾Ğ±ÑŠÑ‘Ğ¼ â€” Ğ¾Ñ‚ 1500 Ğ´Ğ¾ 2000 ÑĞ¸Ğ¼Ğ²Ğ¾Ğ»Ğ¾Ğ²."
            )
        },
        {
            "role": "user",
            "content": "Ğ Ğ°ÑÑĞºĞ°Ğ¶Ğ¸ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ ÑĞºĞ°Ğ·ĞºÑƒ."
        }
    ]

    for attempt in range(3):
        try:
            story = await request_gpt_story(base_messages)
            print(f"\n=== GPT Ğ¡ĞºĞ°Ğ·ĞºĞ° [{attempt+1}] ===\n{story}\n")

            if is_story_ok(story):
                if is_story_finished(story):
                    return ensure_ending(story)

                print("â­ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ Ğ¾Ğ±Ñ€Ñ‹Ğ² â€” GPT Ğ¿Ñ€Ğ¾Ğ´Ğ¾Ğ»Ğ¶Ğ¸Ñ‚ ÑĞºĞ°Ğ·ĞºÑƒ...")
                continuation_messages = [
                    *base_messages,
                    {
                        "role": "assistant",
                        "content": story
                    },
                    {
                        "role": "user",
                        "content": "ĞŸĞ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°, Ğ·Ğ°ĞºĞ¾Ğ½Ñ‡Ğ¸ ÑÑ‚Ñƒ ÑĞºĞ°Ğ·ĞºÑƒ Ğ´Ğ¾ ĞºĞ¾Ğ½Ñ†Ğ°, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ² Ñ„Ğ¸Ğ½Ğ°Ğ» Ğ¸ Ğ¼Ğ¾Ñ€Ğ°Ğ»ÑŒ."
                    }
                ]
                continuation = await request_gpt_story(continuation_messages, max_tokens=600)
                full_story = story + "\n" + continuation
                return ensure_ending(full_story)
        except Exception as e:
            print(f"âŒ ĞŸĞ¾Ğ¿Ñ‹Ñ‚ĞºĞ° {attempt+1}: Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ â€” {e}")

    return "Ğ¡ĞºĞ°Ğ·ĞºĞ° ÑĞ±ĞµĞ¶Ğ°Ğ»Ğ° Ğ² Ğ»ĞµÑ... ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ ĞµÑ‰Ñ‘ Ñ€Ğ°Ğ· Ğ¿Ğ¾Ğ·Ğ¶Ğµ ğŸ¾"

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text(
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ â€” Ğ¡ĞºĞ°Ğ·Ğ¾Ñ‡Ğ½Ğ¸Ğº Ğ¢Ğ¸Ğ¼Ğ¾ÑˆĞ°. âœ¨\nĞĞ°Ğ¿Ğ¸ÑˆĞ¸ /skazka â€” Ğ¸ Ñ Ñ€Ğ°ÑÑĞºĞ°Ğ¶Ñƒ Ñ‚ĞµĞ±Ğµ Ğ´Ğ¾Ğ±Ñ€ÑƒÑ ÑĞºĞ°Ğ·ĞºÑƒ."
    )

async def skazka(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("ĞŸĞ¾Ğ³Ğ¾Ğ´Ğ¸ Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾... Ñ Ğ²ÑĞ¿Ğ¾Ğ¼Ğ¸Ğ½Ğ°Ñ ÑĞºĞ°Ğ·ĞºÑƒ... â˜•")
    story = await generate_fairytale()
    parts = split_by_paragraphs(story)

    for i, part in enumerate(parts, start=1):
        if len(parts) > 1:
            header = f"ğŸ“˜ Ğ§Ğ°ÑÑ‚ÑŒ {i}/{len(parts)}\n"
        else:
            header = ""
        await update.message.reply_text(header + part)

if __name__ == "__main__":
    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("skazka", skazka))

    import threading
    from http.server import BaseHTTPRequestHandler, HTTPServer

    class DummyHandler(BaseHTTPRequestHandler):
        def do_GET(self):
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b'Service is up')

        def do_HEAD(self):
            self.send_response(200)
            self.end_headers()

    def run_dummy_server():
        server = HTTPServer(('0.0.0.0', 8080), DummyHandler)
        server.serve_forever()

    threading.Thread(target=run_dummy_server, daemon=True).start()
    app.run_polling()
